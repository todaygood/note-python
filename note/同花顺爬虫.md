# 爬虫学习

如何建立一个可扩展的cookie池？爬虫必备神器

Cookie池, https://jiaokangyang.com/556.html





【问题解决】关于爬虫被封的处理方法（同花顺数据获取问题）

https://blog.csdn.net/CY19980216/article/details/86647597


首先自然是常规的requests.Session()模块的方法，伪装User-Agent，先定位同花顺，再进入数据中心获取数据。结果甚至连访问都无法做到，后来我尝试复制了一段真实浏览器访问的Cookie加入到session.headers中终于可以实现数据获取；
然而接下来就是无穷无尽了只能获取到前五页的数据的问题了。我尝试了爬取每页伪装一个不同IP（失败，仍然只能五页）；两次访问之间设置一个60~120秒的间隔（稍有起效，但是仍然会被拒绝访问）；最后我甚至猜想会不会是同花顺默认设置如果访问了前五页就不允许访问接下来的页面，于是我尝试用一个随机的顺序去访问这总共71页，结果如你所料——并没有什么P用，访问了五页后照样拒绝访问；
我最后总结下来原因应该是出在Cookie上，可是我又无法做到每次访问换一个新的Cookie，虽然继续增加访问之间的间隔时间是有效果的，但是都间隔2分钟访问一次我还不如自己手动复制页面算了；
这时候我忽然想到了selenium。以前我觉得selenium能做到的事情，我普通爬虫照样能做到，而且selenium需要实际启动浏览器，刷新页面实在是很低效的做法，同样的爬虫我用requests库能爬100页而selenium可能只能爬到30页，因此我一度觉得selenium是一个很鸡肋的爬虫手段。但是现在不同了，requests.Session()模块在同花顺面前成了纸老虎，中看不中用了，于是我重启selenium来进行爬虫；
事实上在selenium只生成一个webdriver对象的情况下仍然会被同花顺限制在五页之类的访问次数，可是如果我每访问一次都重建一个新的webdriver对象则可以避免这种情况；
————————————————
版权声明：本文为CSDN博主「囚生CY」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/CY19980216/article/details/86647597


爬虫:破解同花顺网js加密动态生成请求中所需要的cookie
https://blog.csdn.net/weixin_41406913/article/details/103280900


https://blog.csdn.net/qq_36936730/article/details/104750041


爬虫基础篇
https://blog.csdn.net/welggy/article/details/115358013?spm=1001.2101.3001.6661.1&utm_medium=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1.pc_relevant_paycolumn_v3&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1.pc_relevant_paycolumn_v3&utm_relevant_index=1

# 如何破解同花顺网站的反爬虫

1. 使用代理池来对付“封IP”
https://jishuin.proginn.com/p/763bfbd384a9

2. 使用多个cookie 

3.

